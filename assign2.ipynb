{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b6caee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "stemmer= PorterStemmer()\n",
    "from random import shuffle\n",
    "import re\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70be234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"Humor,Hist,Media,Food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93a26634",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_url = []\n",
    "paths=[]\n",
    "folder_url=str(os.getcwd())+\"\\\\\"+folder+\"\\\\\"\n",
    "docn=1\n",
    "for root, dirs, files in os.walk(folder_url, topdown=False):\n",
    "    for i in files:\n",
    "        paths.append(folder_url+i)\n",
    "        docn+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ab0dc378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data extraction and preprocessing\n",
    "postings={}\n",
    "postings2={}\n",
    "doc=1\n",
    "for path in paths:\n",
    "    newl=[]\n",
    "    file=open(path, 'r')\n",
    "    try:\n",
    "        data=file.read().strip() #stripping white spaces\n",
    "    except UnicodeDecodeError:\n",
    "        a=1\n",
    "        \n",
    "    file.close()\n",
    "    data=data.lower() #lower case\n",
    "    data=re.sub(r'\\d+', '', data) #removing numbers\n",
    "    data=data.translate(str.maketrans(\"\",\"\", string.punctuation)) #removing punctuation\n",
    "    stop_words = set(stopwords.words('english')) # for removing stopwords\n",
    "    tokens=word_tokenize(data) #tokenization\n",
    "    for i in tokens:\n",
    "        j=stemmer.stem(i) # for stemming\n",
    "        if j not in stop_words and len(j)>1:\n",
    "            newl.append(j)\n",
    "            if j not in postings2.keys():\n",
    "                postings2[j]=[doc]\n",
    "            else:\n",
    "                li=postings2[j]\n",
    "                if doc not in li:\n",
    "                    li.append(doc)\n",
    "    postings[doc]=(newl.copy())\n",
    "\n",
    "    doc+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf0e9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(postings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "05d37332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union(d1, d2):\n",
    "    d1=set(d1)\n",
    "    d2=set(d2)\n",
    "    return list(d1 | d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09e49203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(d1, d2):\n",
    "    d1=set(d1)\n",
    "    d2=set(d2)\n",
    "    return list(d1 & d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a94fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jc_fn(qry, postings):\n",
    "    jc={}\n",
    "    ans1=[]\n",
    "    ans2=[]\n",
    "    for i, k in enumerate(postings):\n",
    "        doc_words=postings[k]\n",
    "        ans1=union(doc_words, qry)\n",
    "        ans2=intersection(doc_words, qry)\n",
    "        jc[k]=len(ans2)/len(ans1)\n",
    "    jc=dict(sorted(jc.items(), key=lambda item: item[1], reverse=True))\n",
    "    return jc\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c19009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter String Query: first aid\n",
      "Number of documents: 5\n",
      "kid_diet.txt\n",
      "bigpic1.hum\n",
      "bread.rcp\n",
      "court.quips\n",
      "a-team\n"
     ]
    }
   ],
   "source": [
    "inp_query=input(\"Enter String Query: \")\n",
    "nums=int(input(\"Number of documents: \"))\n",
    "data=inp_query.strip()\n",
    "data=data.lower()\n",
    "data=data.translate(str.maketrans(\"\",\"\", string.punctuation)) #removing punctuation\n",
    "tokens=word_tokenize(data)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "final_tokens=[]\n",
    "\n",
    "for i in tokens:\n",
    "    if i not in stop_words:\n",
    "        final_tokens.append(i) \n",
    "\n",
    "if len(final_tokens)<1:\n",
    "    print(\"no valid tokens\")\n",
    "else:\n",
    "    jc=jc_fn(final_tokens, postings)\n",
    "    for i, k in enumerate(jc):\n",
    "        if i==nums:\n",
    "            break\n",
    "        ans=paths[k].split(\"\\\\\")\n",
    "        print(ans[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dac0faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf\n",
    "def tf_matrix(variant, postings):\n",
    "    ans={}\n",
    "    for i, k in enumerate(postings):\n",
    "        tf={}\n",
    "        words=postings[k]\n",
    "        for j in words:\n",
    "            if j not in tf.keys():\n",
    "                tf[j]=1\n",
    "            else:\n",
    "                tf[j]+=1\n",
    "        ans[k]=tf\n",
    "    if variant==\"raw\":\n",
    "        return ans\n",
    "    ans2={}\n",
    "    for i, k in enumerate(ans):\n",
    "        tf={}\n",
    "        words=ans[k]\n",
    "        for j in words:\n",
    "            fre=words[j]\n",
    "            if variant==\"log\":\n",
    "                score=np.log(1+fre)\n",
    "            elif variant==\"double_norm\":\n",
    "                maxim=max(words.values())\n",
    "                score=0.5+(0.5*(fre/maxim))\n",
    "            elif variant==\"term\":\n",
    "                summation=sum(words.values())\n",
    "                score=fre/summation\n",
    "            elif variant==\"binary\":\n",
    "                if fre>0:\n",
    "                    score=1\n",
    "                else:\n",
    "                    score=0    \n",
    "            tf[j]=score\n",
    "        ans2[k]=tf\n",
    "    return ans2\n",
    "\n",
    "# print(len(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "77257c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idd=0\n",
    "# for i, k in enumerate(ans):\n",
    "#     print(k, ans[k])\n",
    "#     if idd==5:\n",
    "#         break\n",
    "#     idd+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e30bf205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idf\n",
    "idf={}\n",
    "total_docs=len(postings)\n",
    "for i, k in enumerate(postings2):\n",
    "    word_docs=len(postings2[k])\n",
    "    value=np.log(total_docs/word_docs)\n",
    "    idf[k]=value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3b6a87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf\n",
    "def tf_idf_fn(ans):\n",
    "    tf_final={}\n",
    "    for i, k in enumerate(ans):\n",
    "        tf_idf_dict={}\n",
    "        all_words=ans[k]\n",
    "        for i, word in enumerate(all_words):\n",
    "            cur_f1=all_words[word]\n",
    "            cur_idf=idf[word]\n",
    "            f=cur_f1*cur_idf\n",
    "            tf_idf_dict[word]=f\n",
    "        tf_final[k]=tf_idf_dict\n",
    "    return tf_final\n",
    "\n",
    "# idd=0\n",
    "# for i, k in enumerate(tf_final):\n",
    "#     print(k, tf_final[k])\n",
    "#     if idd==5:\n",
    "#         break\n",
    "#     idd+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d73b4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_docs(ans, qry):\n",
    "    tf_idf_sort={}\n",
    "    for word in qry:\n",
    "        for i, k in enumerate(ans):\n",
    "            a_doc=ans[k]\n",
    "            if word in a_doc.keys():\n",
    "                score=a_doc[word]\n",
    "                if k in tf_idf_sort.keys():\n",
    "                    tf_idf_sort[k]+=score\n",
    "                else:\n",
    "                    tf_idf_sort[k]=score\n",
    "                \n",
    "    tf_idf_sort=dict(sorted(tf_idf_sort.items(), key=lambda item: item[1], reverse=True))\n",
    "    return tf_idf_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3eaf557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fn(qry_list, variant, postings,paths):\n",
    "    print(variant, end=\":\\n\")\n",
    "    ans=tf_matrix(variant, postings)\n",
    "    tf_ans=tf_idf_fn(ans)\n",
    "    final_ans=sort_docs(tf_ans, qry_list)\n",
    "    for i, doc_k in enumerate(final_ans):\n",
    "        if i==5:\n",
    "            break\n",
    "        pat=paths[doc_k].split(\"\\\\\")\n",
    "        print(pat[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bb9a49da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary:\n",
      "modemwld.txt\n",
      "adameve.hum\n",
      "humpty.dumpty\n",
      "prawblim.hum\n",
      "candybar.fun\n",
      "raw:\n",
      "candybar.fun\n",
      "modemwld.txt\n",
      "humpty.dumpty\n",
      "prawblim.hum\n",
      "adameve.hum\n",
      "term:\n",
      "deterior.hum\n",
      "socecon.hum\n",
      "jokeju07.txt\n",
      "cybrtrsh.txt\n",
      "flux_fix.txt\n",
      "log:\n",
      "modemwld.txt\n",
      "humpty.dumpty\n",
      "adameve.hum\n",
      "candybar.fun\n",
      "prawblim.hum\n",
      "double_norm:\n",
      "modemwld.txt\n",
      "adameve.hum\n",
      "humpty.dumpty\n",
      "prawblim.hum\n",
      "candybar.fun\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qry_list=postings2.keys()\n",
    "final_fn(qry_list, \"binary\", postings, paths)\n",
    "final_fn(qry_list, \"raw\", postings, paths)\n",
    "final_fn(qry_list, \"term\", postings, paths)\n",
    "final_fn(qry_list, \"log\", postings,paths)\n",
    "final_fn(qry_list, \"double_norm\", postings, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "723061ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "f=open(\"IR-assignment-2-data.txt\", \"r\")\n",
    "data=f.readlines()\n",
    "qid4=[]\n",
    "for line in data:\n",
    "    tokens=list(line.split())\n",
    "    token=tokens[0]\n",
    "    tokens[0]=int(token)\n",
    "    token1=tokens[1]\n",
    "    label=list(token1.split(\":\"))\n",
    "    label=label[1]\n",
    "    if label=='4':\n",
    "        qid4.append(tokens)\n",
    "# print(len(qid4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "382853b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128848"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid44=qid4.copy()\n",
    "qid44.sort(key=lambda x: x[0], reverse=True)\n",
    "newf=open(\"maxDCG\", \"w\")\n",
    "final_t=\"\"\n",
    "for i in qid44:\n",
    "    text=\"\"\n",
    "    text+= ' '.join([str(elem) for elem in i])\n",
    "    final_t+=text+\"\\n\"\n",
    "newf.write(final_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ed0dd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(qid4)\n",
    "rel=[]\n",
    "for i in qid4:\n",
    "    rel.append(i[0])\n",
    "idx=0\n",
    "dcg=0\n",
    "tot=0\n",
    "for i in rel:\n",
    "    tot+=1\n",
    "    dg=2**i- 1\n",
    "    dn=np.log2(idx+2)\n",
    "    dcg+=dg/dn\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "251f6ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.795067144909064\n"
     ]
    }
   ],
   "source": [
    "print(dcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c6aefc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(qid4)\n",
    "rel=[]\n",
    "for i in qid4:\n",
    "    rel.append(i[0])\n",
    "idx=0\n",
    "dcg=0\n",
    "tot=0\n",
    "for i in rel:\n",
    "    tot+=1\n",
    "    dg=2**i- 1\n",
    "    dn=np.log2(idx+2)\n",
    "    dcg+=dg/dn\n",
    "    idx+=1\n",
    "    if(tot==50):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d1e2f597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.829687295288217\n"
     ]
    }
   ],
   "source": [
    "print(dcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57efbf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
